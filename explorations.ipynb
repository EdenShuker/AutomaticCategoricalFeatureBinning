{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "#@formatter:off\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "#@formatter:on"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "type_to_imputer_strategy = {'float64': 'mean', 'object': 'most_frequent'}"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "SEED = 42"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "def get_categorical_columns_by_range_of_uniqueness(df, min_unique, max_unique, target_column):\n",
    "    df = df.drop(target_column, axis=1)\n",
    "    a = df.nunique()\n",
    "    a = a.ge(min_unique) & a.le(max_unique)\n",
    "\n",
    "    return list(a[a].index)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "from src.data_preprocessing import preprocess_data\n",
    "from src.test_binning import get_score_of_classification_model\n",
    "from src.binner import apply_binning_on_column\n",
    "from src.alt_binning import find_optimal_binning_without_frequency\n",
    "import time\n",
    "\n",
    "\n",
    "def test_column(df_train, df_test, target_column_name, categorical_column_name):\n",
    "    start_time = time.time()\n",
    "    optimal_binning = find_optimal_binning_without_frequency(df_train, target_column_name, categorical_column_name)\n",
    "    total_time = time.time() - start_time\n",
    "\n",
    "    df_train_copy = df_train.copy()\n",
    "    df_test_copy = df_test.copy()\n",
    "    new_col_train = apply_binning_on_column(df_train_copy[categorical_column_name], optimal_binning)\n",
    "    df_train_copy[categorical_column_name] = new_col_train\n",
    "    new_col_test = apply_binning_on_column(df_test_copy[categorical_column_name], optimal_binning)\n",
    "    df_test_copy[categorical_column_name] = new_col_test\n",
    "\n",
    "    x_train, y_train, x_test, y_test = preprocess_data(df_train_copy, df_test_copy, target_column_name)\n",
    "    with_binning_score = get_score_of_classification_model(x_train, y_train, x_test, y_test)\n",
    "\n",
    "    new_categories = new_col_train.unique()\n",
    "\n",
    "    return with_binning_score, new_categories, total_time"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "def examine_dataset(df, target_column_name, dataset_name, min_unique, max_unique):\n",
    "    df_columns = df.columns\n",
    "    nan_columns_summary = df.isnull().sum() != 0\n",
    "    nan_columns = nan_columns_summary.index[nan_columns_summary].tolist()\n",
    "\n",
    "    transformers = []\n",
    "    for feature in df_columns:\n",
    "        if feature in nan_columns:\n",
    "            transformers.append(\n",
    "                (f'{feature}_imputer', SimpleImputer(strategy=type_to_imputer_strategy[df[feature].dtype.name]),\n",
    "                 [feature]))\n",
    "        else:\n",
    "            transformers.append((f'{feature}_keeper', 'passthrough', [feature]))\n",
    "\n",
    "    column_trans = ColumnTransformer(transformers)\n",
    "    df_transformed_data = column_trans.fit_transform(df)\n",
    "    df_transformed = pd.DataFrame(data=df_transformed_data, columns=df_columns)\n",
    "\n",
    "    df_train, df_test = train_test_split(df_transformed, test_size=0.25, random_state=SEED)\n",
    "    df_train.reset_index(drop=True, inplace=True)\n",
    "    df_test.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    x_train, y_train, x_test, y_test = preprocess_data(df_train, df_test, target_column_name)\n",
    "\n",
    "    score_without_binning = round(get_score_of_classification_model(x_train=x_train, y_train=y_train, x_test=x_test,\n",
    "                                                                    y_test=y_test), 3)\n",
    "\n",
    "    categorical_columns = get_categorical_columns_by_range_of_uniqueness(df_train, min_unique=min_unique,\n",
    "                                                                         max_unique=max_unique,\n",
    "                                                                         target_column=target_column_name)\n",
    "\n",
    "    success_columns = {}\n",
    "\n",
    "    for column in tqdm(categorical_columns, desc=f\"{dataset_name} Progress\"):\n",
    "        with_binning_score, optimal_binning, total_time = test_column(df_train, df_test, target_column_name,\n",
    "                                                                      categorical_column_name=column)\n",
    "\n",
    "        if with_binning_score > score_without_binning:\n",
    "            success_columns[column] = {\"score\": round(with_binning_score, 3),\n",
    "                                       \"og_unique\": sorted(df_train[column].unique()),\n",
    "                                       \"og_n_unique\": df_train[column].nunique(),\n",
    "                                       \"new_unique\": optimal_binning,\n",
    "                                       \"n_unique\": len(optimal_binning),\n",
    "                                       \"total_time\": total_time}\n",
    "\n",
    "    return success_columns, score_without_binning"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "def get_results(datasets_df, min_unique, max_unique):\n",
    "    model_records = []\n",
    "\n",
    "    for idx, row in tqdm(datasets_df.iterrows(), desc=\"Datasets Progress\", total=len(datasets_df)):\n",
    "        success_columns, score_without_binning = examine_dataset(df=row.df, dataset_name=row[\"Name\"],\n",
    "                                                                 target_column_name=row[\"Target Column\"],\n",
    "                                                                 min_unique=min_unique, max_unique=max_unique)\n",
    "        for col in success_columns:\n",
    "            model_records.append([row[\"Name\"], col, success_columns[col][\"score\"], score_without_binning,\n",
    "                                  success_columns[col][\"og_unique\"], success_columns[col][\"og_n_unique\"],\n",
    "                                  success_columns[col][\"new_unique\"], success_columns[col][\"n_unique\"],\n",
    "                                  success_columns[col][\"total_time\"]])\n",
    "\n",
    "    return model_records"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "read_dataset = lambda x: pd.read_csv(f'data/{x}')\n",
    "\n",
    "churn_modeling = ['churn_modeling', read_dataset(\"churn_modeling/Churn_Modelling.csv\"), 'Exited']\n",
    "titanic = ['titanic', read_dataset(\"titanic/train.csv\"), 'Survived']\n",
    "# home_credit_risk = ['home_credit_risk', read_dataset(\"home_credit_risk/train.csv\"), \"TARGET\"]\n",
    "\n",
    "datasets_df = pd.DataFrame([churn_modeling, titanic], columns=['Name', 'df', 'Target Column'])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Datasets Progress:   0%|          | 0/2 [00:00<?, ?it/s]\n",
      "churn_modeling Progress:   0%|          | 0/1 [00:00<?, ?it/s]\u001B[A\n",
      "churn_modeling Progress: 100%|██████████| 1/1 [00:11<00:00, 11.39s/it]\u001B[A\n",
      "Datasets Progress:  50%|█████     | 1/2 [00:15<00:15, 15.96s/it]\n",
      "titanic Progress:   0%|          | 0/2 [00:00<?, ?it/s]\u001B[A\n",
      "titanic Progress:  50%|█████     | 1/2 [00:00<00:00,  1.72it/s]\u001B[A\n",
      "titanic Progress: 100%|██████████| 2/2 [00:01<00:00,  1.64it/s]\u001B[A\n",
      "Datasets Progress: 100%|██████████| 2/2 [00:17<00:00,  8.72s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": "          Dataset Column Name  Optimal Binning Model Score  \\\n0  churn_modeling      Tenure                       84.280   \n1         titanic       SibSp                       81.614   \n2         titanic       Parch                       81.166   \n\n   Score without Binning                           og_unique  og_n_unique  \\\n0                 83.760  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10]           11   \n1                 80.717               [0, 1, 2, 3, 4, 5, 8]            7   \n2                 80.717               [0, 1, 2, 3, 4, 5, 6]            7   \n\n            new_unique  n_unique  total_time  \n0  [0, 8, 10, 4, 9, 5]         6    7.533731  \n1         [3, 2, 4, 5]         4    0.456467  \n2         [6, 2, 3, 4]         4    0.502581  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Dataset</th>\n      <th>Column Name</th>\n      <th>Optimal Binning Model Score</th>\n      <th>Score without Binning</th>\n      <th>og_unique</th>\n      <th>og_n_unique</th>\n      <th>new_unique</th>\n      <th>n_unique</th>\n      <th>total_time</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>churn_modeling</td>\n      <td>Tenure</td>\n      <td>84.280</td>\n      <td>83.760</td>\n      <td>[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10]</td>\n      <td>11</td>\n      <td>[0, 8, 10, 4, 9, 5]</td>\n      <td>6</td>\n      <td>7.533731</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>titanic</td>\n      <td>SibSp</td>\n      <td>81.614</td>\n      <td>80.717</td>\n      <td>[0, 1, 2, 3, 4, 5, 8]</td>\n      <td>7</td>\n      <td>[3, 2, 4, 5]</td>\n      <td>4</td>\n      <td>0.456467</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>titanic</td>\n      <td>Parch</td>\n      <td>81.166</td>\n      <td>80.717</td>\n      <td>[0, 1, 2, 3, 4, 5, 6]</td>\n      <td>7</td>\n      <td>[6, 2, 3, 4]</td>\n      <td>4</td>\n      <td>0.502581</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "min_unique = 5\n",
    "max_unique = 11\n",
    "\n",
    "model_records = get_results(datasets_df, min_unique=min_unique, max_unique=max_unique)\n",
    "pd.DataFrame(data=model_records,\n",
    "             columns=[\"Dataset\", \"Column Name\", \"Optimal Binning Model Score\", \"Score without Binning\", \"og_unique\",\n",
    "                      \"og_n_unique\", \"new_unique\", \"n_unique\", \"total_time\"])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "auto_bin",
   "language": "python",
   "display_name": "auto_bin_kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
